# XML2PostgreSQL Ingestion

Проект для парсинга XML-файлов и загрузки данных в PostgreSQL через staging-таблицы и COPY FROM STDIN.

В данном проекте выбран **потоковый (streaming) подход к обработке XML** в сочетании с **bulk-загрузкой данных в PostgreSQL через COPY**, поскольку размер входных данных (до ~1 TB) существенно превышает объём доступной оперативной памяти. Использование `lxml.iterparse` позволяет читать и обрабатывать XML инкрементально, освобождая память сразу после обработки элементов, а архитектура producer/consumer с ограниченной очередью обеспечивает естественный backpressure и стабильное потребление памяти независимо от размера файла.

Для загрузки в базу данных применяются **staging-таблицы и COPY FROM STDIN**, что является наиболее производительным и надёжным способом массовой вставки данных в PostgreSQL. Индексы и ограничения создаются только после завершения загрузки, чтобы не снижать throughput. Параллельная запись несколькими worker-процессами позволяет эффективно использовать ресурсы БД, а ретраи и graceful shutdown делают пайплайн устойчивым к временным сбоям. Такой подход соответствует best practices data engineering и хорошо масштабируется при росте объёма данных без усложнения архитектуры.


## 1. Архитектура

Обработка данных разделена на независимые этапы, связанные моделью producer / consumer:

**1. Producer (парсер XML)**
Отвечает за потоковое чтение XML-файла и извлечение данных.
**2. Очередь с ограничением размера (bounded queue)**
Обеспечивает backpressure и контроль памяти.
**3. Consumer-процессы (writer’ы)**
Параллельно загружают данные в PostgreSQL через COPY FROM STDIN.
**4. Staging-слой в базе данных**
Используется для быстрой массовой загрузки и последующей финализации.

### 1. Потоковая обработка XML

Чтение XML реализовано с использованием lxml.iterparse, что позволяет обрабатывать файл инкрементально, не загружая его целиком в память. После обработки каждого XML-элемента память освобождается (clear() и удаление обработанных узлов), что гарантирует стабильное потребление RAM независимо от размера входного файла.

При частично повреждённом XML используется режим recover, некорректные записи пропускаются и учитываются в метриках, не приводя к остановке всего пайплайна.

### 2. Producer / Consumer и backpressure

Парсинг XML и запись в базу данных выполняются параллельно и изолированы друг от друга:

Producer извлекает данные из XML и формирует батчи фиксированного размера (по количеству строк и приблизительному объёму в байтах).

Батчи передаются через ограниченную очередь (multiprocessing.Queue с maxsize).

Если consumer-процессы не успевают обрабатывать данные, очередь заполняется, и producer автоматически блокируется — таким образом реализуется backpressure и предотвращается рост потребления памяти.

### 3. Батчирование и загрузка в PostgreSQL

Для максимальной производительности данные загружаются не по одной строке, а батчами через COPY FROM STDIN.
Запись осуществляется в staging-таблицы, в которых отсутствуют индексы и ограничения, что позволяет достичь максимального throughput.

Consumer-процессы работают независимо друг от друга и используют ретраи с exponential backoff при временных ошибках базы данных. При фатальных ошибках пайплайн корректно останавливается.

### 4. Финализация данных

После завершения загрузки данные из staging-таблиц переносятся в финальные таблицы. На этом этапе выполняются:

- создание индексов,
- добавление primary key и foreign key,
- возможная дедупликация или merge-логика.

Такой подход позволяет изолировать «дорогие» операции от основного ingestion-процесса и не снижать скорость загрузки.

### 5. Управление и наблюдаемость

Вся программа управляется через CLI и поддерживает:

- инициализацию схемы БД,
- запуск ingestion,
- очистку staging-таблиц,
- финализацию данных.

Во время работы пайплайна собираются метрики (обработанные записи, батчи, ошибки, throughput), которые периодически логируются. Это позволяет оценивать прогресс и производительность без дополнительной нагрузки на систему.

### Ключевые архитектурные принципы

- Streaming first — данные обрабатываются по мере чтения.
- Bounded memory — размер буферов жёстко ограничен.
- Bulk operations — максимальное использование возможностей PostgreSQL.
- Fail-tolerant — ошибки не приводят к падению всего процесса.
- Scalable — количество writer-процессов настраивается.

## 2. Установка

##### 2.1. Требования
- **Python**: 3.10+
- **PostgreSQL**: 13+ (рекомендуется 14+)
- **Операционная система**: Linux / macOS  
  (Windows — без гарантий производительности)

##### 2.2. Основные библиотеки
- **lxml** — потоковый парсинг XML (`iterparse`)
- **SQLAlchemy** — управление соединениями и DDL
- **psycopg2** или **psycopg3** — COPY FROM STDIN
- **python-dotenv** — конфигурация через `.env`

##### 2.3. Настройка переменных окружения

Необходимо создать .env со следующими параметрами:
```
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
POSTGRES_USER=xml2pg_user
POSTGRES_PASSWORD=xml2pg_password
POSTGRES_DB=xml2pg
```

##### 2.4. Запуск контейнера с PostgreSQL
```
docker compose up -d
```

##### 2.5. Установка зависимостей
```
uv sync
```

##### 2.6. Генерация тестового xml файла
```
python -m src.xml.sample_generator --out data/sample.xml --groups 1000000 --events-per-group 2
```
- out - путь сгенерированного файла
- groups - количество групп в файле
- events-per-group - количество событий в одной группе

## 3. Запуск
```
python src/main.py
```

## 4. Провекра работы программы

##### Подключение к БД:
```
docker exec -it xml2pg-postgres psql -U xml2pg_user -d xml2pg
```

##### Посмотреть таблицы:
```
\d
```

##### Проверка staging таблиц:
```
SELECT count(*) FROM stg_group_event;
SELECT count(*) FROM stg_event;
```
##### Проверка финальныех таблиц:
```
SELECT * FROM group_event LIMIT 10;
SELECT * FROM event LIMIT 10;
```

## 5. Запуск тестов
```
pytest -q
```

## 6. Структура проект
```
xml2pg-ingestion/
├── src/
│   ├── main.py                # Точка входа
│   ├── db/                    
│   │   ├── connection.py      # Подключение к PostgreSQL
│   │   ├── copy.py            # COPY FROM STDIN помощник
│   │   ├── ddl.py             # Инициализация схемы
│   │   ├── finalize.py        # Финализация данных
│   │   ├── models.py          # ORM и Table модели таблиц БД
│   │   └── staging.py         # COPY в staging-таблицы
│   ├── pipeline/              
│   │   ├── batching.py        # Батчирование по rows / bytes
│   │   ├── consumer.py        # COPY в PostgreSQL
│   │   ├── coordinator.py     # Оркестрация процессов
│   │   ├── metrics.py         # Метрики пайплайна 
│   │   └── producer.py        # Потоковый парсинг XML
│   ├── settings/              
│   │   ├── env_settings.py    # Загрузка параметров из .env
│   │   ├── ini_settings.py    # Загрузка параметров из .ini
│   │   ├── logging.py         # Настройки логгера
│   │   └── settings.py        # Загрузка настроек программы
│   ├── utils/
│   │   └── errors.py          # Кастомные ошибки
│   └── xml/                   
│       ├── parser.py          # Извлечение сущностей
│       ├── reader.py          # Streaming iterparse + cleanup
│       └── sample_generator.py # Генератор тестового XML
└── tests/                     
    ├── test_batching.py/      # Тесты батчинга                
    ├── test_producer.py/      # Тесты producer                
    └── test_xml_parser.py/    # Тесты парсера XML
```
## 7. Лицензия

#### MIT

## 8. Возможные улучшения
- Больше тестов (consumer, coordinator, БД)
- Binary COPY вместо текстового формата
- Динамическая адаптация размеров батчей
- Расширенные метрики и мониторинг (Возможно добавить Prometheus+Grafana)